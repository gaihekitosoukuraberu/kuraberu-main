name: Google Drive to Xserver FTP Sync

on:
  workflow_dispatch:
  schedule:
    # ğŸ’° 2025-12ä»¥é™ï¼šç„¡æ–™æ ç¯€ç´„ã®ãŸã‚1æ™‚é–“ãŠãã«å¤‰æ›´ï¼ˆ15åˆ†â†’60åˆ†ï¼‰
    # æœˆé–“å®Ÿè¡Œæ™‚é–“: 24å›/æ—¥ Ã— 30æ—¥ Ã— 1åˆ† = 720åˆ† < 2,000åˆ†ï¼ˆç„¡æ–™æ ï¼‰
    - cron: "0 * * * *"  # æ¯æ™‚0åˆ†ã«å®Ÿè¡Œï¼ˆ1æ™‚é–“ãŠãï¼‰

jobs:
  sync:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2 packaging

      - name: Create sync script
        run: |
          cat > sync_drive_to_ftp.py << 'EOF'
          import os
          import json
          import ftplib
          import tempfile
          import re
          from datetime import datetime, timedelta
          from google.oauth2 import service_account
          from googleapiclient.discovery import build

          def get_drive_service():
              creds_json = os.environ.get('GOOGLE_CREDENTIALS')
              creds_dict = json.loads(creds_json)
              credentials = service_account.Credentials.from_service_account_info(
                  creds_dict,
                  scopes=['https://www.googleapis.com/auth/drive.readonly']
              )
              service = build('drive', 'v3', credentials=credentials)
              print("âœ… Google Drive APIèªè¨¼æˆåŠŸ")
              return service

          def find_gaihekikuraberu_folder(service):
              query = "name='gaihekikuraberu-hp-files' and mimeType='application/vnd.google-apps.folder'"
              results = service.files().list(q=query, fields='files(id, name)').execute()
              folders = results.get('files', [])
              if not folders:
                  print("âŒ ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                  return None
              folder_id = folders[0]['id']
              print(f"âœ… ãƒ•ã‚©ãƒ«ãƒ€æ¤œå‡º: {folders[0]['name']} (ID: {folder_id})")
              return folder_id

          def get_recent_html_files(service, folder_id, minutes=43200):  # 30æ—¥é–“
              cutoff_time = datetime.utcnow() - timedelta(minutes=minutes)
              cutoff_iso = cutoff_time.isoformat() + 'Z'
              query = f"'{folder_id}' in parents and name contains '.html' and modifiedTime > '{cutoff_iso}'"
              results = service.files().list(
                  q=query,
                  fields='files(id, name, modifiedTime, size)',
                  orderBy='modifiedTime desc'
              ).execute()
              files = results.get('files', [])
              print(f"ğŸ” æ¤œç´¢æ¡ä»¶: {minutes}åˆ†ä»¥å†…ã®æ›´æ–°ãƒ•ã‚¡ã‚¤ãƒ«")
              print(f"ğŸ“ æ¤œå‡ºãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files)}")
              for file in files:
                  print(f"  - {file['name']} (æ›´æ–°: {file['modifiedTime']}, ã‚µã‚¤ã‚º: {file.get('size', 'ä¸æ˜')})")
              return files

          def parse_filename(filename):
              print(f"ğŸ” ãƒ‡ãƒãƒƒã‚°: å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«å='{filename}'")
              print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åã®é•·ã•: {len(filename)}")
              print(f"ğŸ” ãƒ•ã‚¡ã‚¤ãƒ«åã®repr: {repr(filename)}")
              
              pattern = r'^([^-]+)-(.+)-index\.html$'
              print(f"ğŸ” ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³: {pattern}")
              
              m = re.match(pattern, filename)
              
              if m:
                  prefecture = m.group(1)
                  company = m.group(2)
                  print(f"âœ… ãƒãƒƒãƒæˆåŠŸ! prefecture={prefecture}, company={company}")
                  result = {
                      "citySlug": prefecture,
                      "companySlug": company,
                      "remotePath": f"{prefecture}/{company}/index.html"
                  }
                  return result
              else:
                  print(f"âŒ æ­£è¦è¡¨ç¾ãƒãƒƒãƒå¤±æ•—")
                  print(f"ğŸ” ãƒ†ã‚¹ãƒˆ: filename.endswith('-index.html') = {filename.endswith('-index.html')}")
                  print(f"ğŸ” ãƒ†ã‚¹ãƒˆ: '-' in filename = {'-' in filename}")
                  return None

          def download_file_from_drive(service, file_id, destination):
              from googleapiclient.http import MediaIoBaseDownload
              import io
              request = service.files().get_media(fileId=file_id)
              fh = io.FileIO(destination, 'wb')
              downloader = MediaIoBaseDownload(fh, request)
              done = False
              while not done:
                  status, done = downloader.next_chunk()
              print(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {destination}")
              return True

          def create_ftp_directory(ftp, path):
              parts = path.split('/')
              for i in range(1, len(parts) + 1):
                  subpath = '/'.join(parts[:i])
                  try:
                      ftp.mkd(subpath)
                      print(f"ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {subpath}")
                  except Exception:
                      pass

          def upload_to_ftp(local_file, parsed_info):
              ftp = ftplib.FTP(os.environ['FTP_HOST'])
              ftp.login(os.environ['FTP_USERNAME'], os.environ['FTP_PASSWORD'])
              ftp.cwd('/gaihekikuraberu.com/public_html')
              path = f"{parsed_info['citySlug']}/{parsed_info['companySlug']}"
              create_ftp_directory(ftp, path)
              ftp.cwd(f"/gaihekikuraberu.com/public_html/{path}")
              with open(local_file, 'rb') as f:
                  ftp.storbinary('STOR index.html', f)
              ftp.quit()
              print(f"âœ… FTPã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {parsed_info['remotePath']}")
              return True

          def main():
              print("ğŸš€ Google Drive â†’ FTP è‡ªå‹•åŒæœŸé–‹å§‹")
              print(f"â° å®Ÿè¡Œæ™‚åˆ»: {datetime.now().isoformat()}")
              service = get_drive_service()
              folder_id = find_gaihekikuraberu_folder(service)
              if not folder_id:
                  return
              files = get_recent_html_files(service, folder_id)
              if not files:
                  print("â„¹ï¸ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ãªã—")
                  return
              success_count = 0
              for file in files:
                  name = file['name']
                  fid = file['id']
                  print(f"\nğŸ“ å‡¦ç†é–‹å§‹: {name}")
                  parsed = parse_filename(name)
                  if not parsed:
                      print(f"âš ï¸ ã‚¹ã‚­ãƒƒãƒ—: {name}")
                      continue
                  tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.html')
                  tmp.close()
                  download_file_from_drive(service, fid, tmp.name)
                  upload_to_ftp(tmp.name, parsed)
                  os.unlink(tmp.name)
                  print(f"ğŸ‰ {name} åŒæœŸå®Œäº†")
                  success_count += 1
              print(f"\nâœ… åŒæœŸå‡¦ç†å®Œäº†: {success_count}/{len(files)} ãƒ•ã‚¡ã‚¤ãƒ«æˆåŠŸ")

          if __name__ == "__main__":
              main()
          EOF

      - name: Run sync
        run: python sync_drive_to_ftp.py
        env:
          FTP_HOST: ${{ secrets.FTP_HOST }}
          FTP_USERNAME: ${{ secrets.FTP_USERNAME }}
          FTP_PASSWORD: ${{ secrets.FTP_PASSWORD }}
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      - name: Complete
        run: echo "ğŸ‰ åŒæœŸå®Œäº† at $(date)"
